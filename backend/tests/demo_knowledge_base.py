#!/usr/bin/env python3
"""
åç«¯æœåŠ¡æµ‹è¯•è„šæœ¬
æµ‹è¯•å®Œæ•´çš„çŸ¥è¯†åº“APIç«¯ç‚¹å’Œæ–‡æ¡£å¤„ç†åŠŸèƒ½
"""
import asyncio
import aiohttp
from typing import Dict, Any, List
import io

# åç«¯æœåŠ¡åœ°å€
BASE_URL = "http://0.0.0.0:8000"

class BackendTester:
    """åç«¯æœåŠ¡æµ‹è¯•ç±»"""
    
    def __init__(self, base_url: str = BASE_URL):
        self.base_url = base_url
        self.session = None
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def test_health(self) -> Dict[str, Any]:
        """æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        async with self.session.get(f"{self.base_url}/health") as resp:
            return await resp.json()
    
    async def test_status(self) -> Dict[str, Any]:
        """æµ‹è¯•çŠ¶æ€ç«¯ç‚¹"""
        async with self.session.get(f"{self.base_url}/status") as resp:
            return await resp.json()
    
    async def create_knowledge_base(self, name: str, description: str = "", datasource_id: str = "demo") -> Dict[str, Any]:
        """åˆ›å»ºçŸ¥è¯†åº“"""
        payload = {
            "name": name,
            "description": description,
            "datasource_id": datasource_id,
            "config": {
                "enable_kg": True,
                "enable_vector": True,
                "chunk_size": 512,
                "chunk_overlap": 50,
                "embedding_model": "sentence-bert",
                "kg_model": "relation-extraction-v1",
                "index_type": "hnsw",
                "similarity_threshold": 0.7
            },
            "tags": ["demo", "test"],
            "auto_build": True
        }
        async with self.session.post(
            f"{self.base_url}/api/v1/knowledge-base/create", 
            json=payload
        ) as resp:
            return await resp.json()
    
    async def get_knowledge_base_status(self, kb_id: str) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“çŠ¶æ€"""
        async with self.session.get(
            f"{self.base_url}/api/v1/knowledge-base/{kb_id}/build/status"
        ) as resp:
            return await resp.json()
    
    async def upload_document(self, file_content: str, filename: str, kb_id: str, process_immediately: bool = True) -> Dict[str, Any]:
        """ä¸Šä¼ æ–‡æ¡£"""
        data = aiohttp.FormData()
        data.add_field('files', io.BytesIO(file_content.encode('utf-8')), filename=filename)
        data.add_field('kb_id', kb_id)
        data.add_field('process_immediately', str(process_immediately).lower())
        
        async with self.session.post(
            f"{self.base_url}/api/v1/document/upload",
            data=data
        ) as resp:
            return await resp.json()
    
    async def build_knowledge_base(self, kb_id: str) -> Dict[str, Any]:
        """æ„å»ºçŸ¥è¯†åº“"""
        async with self.session.post(
            f"{self.base_url}/api/v1/knowledge-base/{kb_id}/build"
        ) as resp:
            return await resp.json()
    
    async def search_knowledge_base(self, kb_id: str, query: str, search_type: str = "hybrid") -> Dict[str, Any]:
        """æœç´¢çŸ¥è¯†åº“"""
        payload = {
            "query": query,
            "search_type": search_type,
            "top_k": 10,
            "score_threshold": 0.5,
            "enable_rerank": True,
            "include_metadata": True,
            "highlight": True,
            "expand_context": False
        }
        async with self.session.post(
            f"{self.base_url}/api/v1/knowledge-base/{kb_id}/search",
            json=payload
        ) as resp:
            return await resp.json()
    
    async def delete_knowledge_base(self, kb_id: str) -> Dict[str, Any]:
        """åˆ é™¤çŸ¥è¯†åº“"""
        async with self.session.delete(
            f"{self.base_url}/api/v1/knowledge-base/{kb_id}"
        ) as resp:
            return await resp.json()
    
    async def validate_knowledge_base(self, kb_id: str) -> Dict[str, Any]:
        """éªŒè¯çŸ¥è¯†åº“"""
        async with self.session.post(
            f"{self.base_url}/api/v1/knowledge-base/{kb_id}/validate"
        ) as resp:
            return await resp.json()
    
    async def get_knowledge_base_info(self, kb_id: str) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“è¯¦ç»†ä¿¡æ¯"""
        async with self.session.get(
            f"{self.base_url}/api/v1/knowledge-base/{kb_id}"
        ) as resp:
            return await resp.json()
    
    async def list_knowledge_bases(self, limit: int = 10, offset: int = 0) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“åˆ—è¡¨"""
        params = {"limit": limit, "offset": offset}
        async with self.session.get(
            f"{self.base_url}/api/v1/knowledge-base/",
            params=params
        ) as resp:
            return await resp.json()
    
    async def get_document_info(self, file_id: str) -> Dict[str, Any]:
        """è·å–æ–‡æ¡£è¯¦ç»†ä¿¡æ¯"""
        async with self.session.get(
            f"{self.base_url}/api/v1/document/{file_id}"
        ) as resp:
            return await resp.json()
    
    async def get_document_content(self, file_id: str, include_metadata: bool = True) -> Dict[str, Any]:
        """è·å–æ–‡æ¡£å†…å®¹"""
        params = {"include_metadata": include_metadata}
        async with self.session.get(
            f"{self.base_url}/api/v1/document/{file_id}/content",
            params=params
        ) as resp:
            return await resp.json()
    
    async def list_documents(self, kb_id: str, limit: int = 10, offset: int = 0) -> Dict[str, Any]:
        """è·å–æ–‡æ¡£åˆ—è¡¨"""
        params = {"kb_id": kb_id, "limit": limit, "offset": offset}
        async with self.session.get(
            f"{self.base_url}/api/v1/document/",
            params=params
        ) as resp:
            return await resp.json()
    
    async def delete_document(self, file_id: str) -> Dict[str, Any]:
        """åˆ é™¤æ–‡æ¡£"""
        async with self.session.delete(
            f"{self.base_url}/api/v1/document/{file_id}"
        ) as resp:
            return await resp.json()

def create_sample_documents() -> List[Dict[str, str]]:
    """åˆ›å»ºç¤ºä¾‹æ–‡æ¡£"""
    return [
        {
            "filename": "machine_learning_intro.txt",
            "content": """# æœºå™¨å­¦ä¹ åŸºç¡€

æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒåˆ†æ”¯ï¼Œé€šè¿‡ç®—æ³•ä½¿è®¡ç®—æœºä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ è§„å¾‹ã€‚

## ä¸»è¦ç®—æ³•ç±»å‹

### ç›‘ç£å­¦ä¹ 
- çº¿æ€§å›å½’ï¼šé¢„æµ‹è¿ç»­å€¼
- é€»è¾‘å›å½’ï¼šåˆ†ç±»é—®é¢˜
- å†³ç­–æ ‘ï¼šåŸºäºè§„åˆ™çš„åˆ†ç±»
- éšæœºæ£®æ—ï¼šé›†æˆå­¦ä¹ æ–¹æ³•
- æ”¯æŒå‘é‡æœºï¼šæœ€å¤§é—´éš”åˆ†ç±»å™¨

### æ— ç›‘ç£å­¦ä¹ 
- Kå‡å€¼èšç±»ï¼šæ•°æ®åˆ†ç»„
- å±‚æ¬¡èšç±»ï¼šæ„å»ºèšç±»æ ‘
- ä¸»æˆåˆ†åˆ†æï¼šé™ç»´æŠ€æœ¯
- å¼‚å¸¸æ£€æµ‹ï¼šè¯†åˆ«å¼‚å¸¸æ•°æ®ç‚¹

### å¼ºåŒ–å­¦ä¹ 
- Qå­¦ä¹ ï¼šåŸºäºä»·å€¼çš„æ–¹æ³•
- ç­–ç•¥æ¢¯åº¦ï¼šç›´æ¥ä¼˜åŒ–ç­–ç•¥
- Actor-Criticï¼šç»“åˆä»·å€¼å’Œç­–ç•¥

## åº”ç”¨åœºæ™¯

æœºå™¨å­¦ä¹ åœ¨å„è¡Œä¸šéƒ½æœ‰å¹¿æ³›åº”ç”¨ï¼š
- é‡‘èï¼šé£é™©è¯„ä¼°ã€æ¬ºè¯ˆæ£€æµ‹
- åŒ»ç–—ï¼šç–¾ç—…è¯Šæ–­ã€è¯ç‰©å‘ç°  
- é›¶å”®ï¼šæ¨èç³»ç»Ÿã€éœ€æ±‚é¢„æµ‹
- äº¤é€šï¼šè‡ªåŠ¨é©¾é©¶ã€è·¯å¾„ä¼˜åŒ–
- åˆ¶é€ ï¼šè´¨é‡æ§åˆ¶ã€é¢„æµ‹æ€§ç»´æŠ¤
"""
        },
        {
            "filename": "data_science_tools.md",
            "content": """# æ•°æ®ç§‘å­¦å·¥å…·ç”Ÿæ€

## Pythonç”Ÿæ€ç³»ç»Ÿ

### æ•°æ®å¤„ç†
- **Pandas**: æ•°æ®åˆ†æå’Œæ“ä½œåº“
- **NumPy**: ç§‘å­¦è®¡ç®—åŸºç¡€åº“
- **Dask**: å¤§è§„æ¨¡æ•°æ®å¹¶è¡Œå¤„ç†

### æœºå™¨å­¦ä¹ 
- **Scikit-learn**: é€šç”¨æœºå™¨å­¦ä¹ åº“
- **TensorFlow**: æ·±åº¦å­¦ä¹ æ¡†æ¶
- **PyTorch**: åŠ¨æ€å›¾æ·±åº¦å­¦ä¹ 
- **XGBoost**: æ¢¯åº¦æå‡ç®—æ³•

### å¯è§†åŒ–
- **Matplotlib**: åŸºç¡€ç»˜å›¾åº“
- **Seaborn**: ç»Ÿè®¡å¯è§†åŒ–
- **Plotly**: äº¤äº’å¼å›¾è¡¨
- **Bokeh**: Webå¯è§†åŒ–

## Rè¯­è¨€å·¥å…·

### ç»Ÿè®¡åˆ†æ
- **ggplot2**: å›¾å½¢è¯­æ³•å¯è§†åŒ–
- **dplyr**: æ•°æ®æ“ä½œ
- **tidyr**: æ•°æ®æ•´ç†
- **caret**: åˆ†ç±»å’Œå›å½’è®­ç»ƒ

## å¤§æ•°æ®å·¥å…·

### åˆ†å¸ƒå¼è®¡ç®—
- **Apache Spark**: å¤§è§„æ¨¡æ•°æ®å¤„ç†
- **Hadoop**: åˆ†å¸ƒå¼å­˜å‚¨å’Œè®¡ç®—
- **Kafka**: æµæ•°æ®å¤„ç†

### æ•°æ®åº“
- **MongoDB**: æ–‡æ¡£æ•°æ®åº“
- **Cassandra**: åˆ—æ—æ•°æ®åº“
- **Redis**: å†…å­˜æ•°æ®åº“
"""
        },
        {
            "filename": "deep_learning.txt",
            "content": """# æ·±åº¦å­¦ä¹ æ¦‚è¿°

æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é¢†åŸŸï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å¤æ‚æ¨¡å¼ã€‚

## ç¥ç»ç½‘ç»œæ¶æ„

### åŸºç¡€ç½‘ç»œ
1. **å…¨è¿æ¥ç½‘ç»œï¼ˆDNNï¼‰**
   - ç»“æ„ï¼šè¾“å…¥å±‚ â†’ éšè—å±‚ â†’ è¾“å‡ºå±‚
   - åº”ç”¨ï¼šåˆ†ç±»ã€å›å½’é—®é¢˜
   - ä¼˜ç‚¹ï¼šé€šç”¨æ€§å¼º
   - ç¼ºç‚¹ï¼šå‚æ•°å¤šï¼Œæ˜“è¿‡æ‹Ÿåˆ

2. **å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰**
   - ç»“æ„ï¼šå·ç§¯å±‚ â†’ æ± åŒ–å±‚ â†’ å…¨è¿æ¥å±‚
   - åº”ç”¨ï¼šå›¾åƒè¯†åˆ«ã€è®¡ç®—æœºè§†è§‰
   - ä¼˜ç‚¹ï¼šå‚æ•°å…±äº«ï¼Œå¹³ç§»ä¸å˜æ€§
   - ç»å…¸æ¨¡å‹ï¼šLeNet, AlexNet, ResNet

3. **å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰**
   - ç»“æ„ï¼šå¸¦è®°å¿†çš„å¾ªç¯è¿æ¥
   - åº”ç”¨ï¼šåºåˆ—æ•°æ®å¤„ç†
   - å˜ç§ï¼šLSTM, GRU
   - åº”ç”¨åœºæ™¯ï¼šè¯­è¨€æ¨¡å‹ã€æ—¶é—´åºåˆ—

### ç°ä»£æ¶æ„
4. **Transformer**
   - æ ¸å¿ƒï¼šè‡ªæ³¨æ„åŠ›æœºåˆ¶
   - ä¼˜åŠ¿ï¼šå¹¶è¡Œè®¡ç®—ã€é•¿è·ç¦»ä¾èµ–
   - åº”ç”¨ï¼šè‡ªç„¶è¯­è¨€å¤„ç†
   - ä»£è¡¨æ¨¡å‹ï¼šBERT, GPT, T5

5. **ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰**
   - ç»“æ„ï¼šç”Ÿæˆå™¨ vs åˆ¤åˆ«å™¨
   - åº”ç”¨ï¼šå›¾åƒç”Ÿæˆã€æ•°æ®å¢å¼º
   - å˜ç§ï¼šDCGAN, StyleGAN, CycleGAN

## è®­ç»ƒæŠ€å·§

### ä¼˜åŒ–ç®—æ³•
- SGDï¼šéšæœºæ¢¯åº¦ä¸‹é™
- Adamï¼šè‡ªé€‚åº”å­¦ä¹ ç‡
- RMSpropï¼šå‡æ–¹æ ¹ä¼ æ’­

### æ­£åˆ™åŒ–æŠ€æœ¯
- Dropoutï¼šéšæœºä¸¢å¼ƒç¥ç»å…ƒ
- Batch Normalizationï¼šæ‰¹æ ‡å‡†åŒ–
- Early Stoppingï¼šæ—©åœæ³•

### æ•°æ®å¢å¼º
- å›¾åƒï¼šæ—‹è½¬ã€ç¿»è½¬ã€ç¼©æ”¾
- æ–‡æœ¬ï¼šåŒä¹‰è¯æ›¿æ¢ã€å›è¯‘
- éŸ³é¢‘ï¼šå™ªå£°æ·»åŠ ã€æ—¶é—´æ‹‰ä¼¸
"""
        }
    ]

async def demonstrate_backend_api():
    """æ¼”ç¤ºåç«¯APIåŠŸèƒ½"""
    print("ğŸ¯ åç«¯æœåŠ¡APIæµ‹è¯•")
    print("=" * 50)
    
    async with BackendTester() as tester:
        # æ­¥éª¤1: æµ‹è¯•æœåŠ¡å¥åº·çŠ¶å†µ
        print(f"\nğŸ”§ æ­¥éª¤1: æµ‹è¯•æœåŠ¡å¥åº·çŠ¶å†µ")
        try:
            health = await tester.test_health()
            print(f"âœ“ å¥åº·æ£€æŸ¥: {health}")
            
            status = await tester.test_status()
            print(f"âœ“ æœåŠ¡çŠ¶æ€: {status}")
        except Exception as e:
            print(f"âŒ æœåŠ¡è¿æ¥å¤±è´¥: {str(e)}")
            print("è¯·ç¡®ä¿åç«¯æœåŠ¡è¿è¡Œåœ¨ http://0.0.0.0:8000")
            return None
        
        # æ­¥éª¤2: åˆ›å»ºçŸ¥è¯†åº“
        print(f"\nğŸ“š æ­¥éª¤2: åˆ›å»ºçŸ¥è¯†åº“")
        kb_name = "demo-ml-knowledge-base"
        try:
            kb_result = await tester.create_knowledge_base(
                name=kb_name,
                description="æœºå™¨å­¦ä¹ å’Œæ•°æ®ç§‘å­¦æ¼”ç¤ºçŸ¥è¯†åº“"
            )
            print(f"âœ“ çŸ¥è¯†åº“åˆ›å»ºç»“æœ: {kb_result}")
            kb_id = kb_result.get("id") or kb_result.get("kb_id")
            if not kb_id:
                print("âŒ æ— æ³•è·å–çŸ¥è¯†åº“ID")
                return None
        except Exception as e:
            print(f"âŒ çŸ¥è¯†åº“åˆ›å»ºå¤±è´¥: {str(e)}")
            return None
        
        # æ­¥éª¤3: ä¸Šä¼ ç¤ºä¾‹æ–‡æ¡£
        print(f"\nğŸ“„ æ­¥éª¤3: ä¸Šä¼ ç¤ºä¾‹æ–‡æ¡£")
        documents = create_sample_documents()
        uploaded_files = []
        
        for doc in documents:
            try:
                result = await tester.upload_document(
                    doc["content"], 
                    doc["filename"],
                    kb_id
                )
                print(f"âœ“ ä¸Šä¼ æ–‡æ¡£ {doc['filename']}: {result}")
                if result.get("uploaded_files"):
                    for uploaded_file in result["uploaded_files"]:
                        uploaded_files.append(uploaded_file["id"])
                elif result.get("file_id"):
                    uploaded_files.append(result["file_id"])
            except Exception as e:
                print(f"âŒ æ–‡æ¡£ä¸Šä¼ å¤±è´¥ {doc['filename']}: {str(e)}")
        
        # æ­¥éª¤4: æ„å»ºçŸ¥è¯†åº“
        print(f"\nğŸ—ï¸  æ­¥éª¤4: æ„å»ºçŸ¥è¯†åº“")
        try:
            build_result = await tester.build_knowledge_base(kb_id)
            print(f"âœ“ çŸ¥è¯†åº“æ„å»ºå¯åŠ¨: {build_result}")
        except Exception as e:
            print(f"âŒ çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {str(e)}")
        
        # æ­¥éª¤5: æ£€æŸ¥æ„å»ºçŠ¶æ€
        print(f"\nğŸ” æ­¥éª¤5: æ£€æŸ¥æ„å»ºçŠ¶æ€")
        for i in range(10):  # æœ€å¤šæ£€æŸ¥10æ¬¡
            try:
                status = await tester.get_knowledge_base_status(kb_id)
                print(f"  æ£€æŸ¥ {i+1}/10: {status}")
                
                if status.get("status") == "ready":
                    print("âœ“ çŸ¥è¯†åº“æ„å»ºå®Œæˆ")
                    break
                elif status.get("status") == "failed":
                    print("âŒ çŸ¥è¯†åº“æ„å»ºå¤±è´¥")
                    break
                
                await asyncio.sleep(2)  # ç­‰å¾…2ç§’å†æ£€æŸ¥
            except Exception as e:
                print(f"âŒ çŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}")
                break
        
        # æ­¥éª¤6: éªŒè¯çŸ¥è¯†åº“
        print(f"\nğŸ”¬ æ­¥éª¤6: éªŒè¯çŸ¥è¯†åº“")
        try:
            validation = await tester.validate_knowledge_base(kb_id)
            print(f"âœ“ çŸ¥è¯†åº“éªŒè¯ç»“æœ: {validation}")
        except Exception as e:
            print(f"âŒ çŸ¥è¯†åº“éªŒè¯å¤±è´¥: {str(e)}")
        
        # æ­¥éª¤7: è·å–çŸ¥è¯†åº“è¯¦ç»†ä¿¡æ¯
        print(f"\nğŸ“‹ æ­¥éª¤7: è·å–çŸ¥è¯†åº“è¯¦ç»†ä¿¡æ¯")
        try:
            kb_info = await tester.get_knowledge_base_info(kb_id)
            print(f"âœ“ çŸ¥è¯†åº“è¯¦ç»†ä¿¡æ¯: {kb_info}")
        except Exception as e:
            print(f"âŒ è·å–çŸ¥è¯†åº“ä¿¡æ¯å¤±è´¥: {str(e)}")
        
        # æ­¥éª¤8: æµ‹è¯•æœç´¢åŠŸèƒ½
        print(f"\nğŸ” æ­¥éª¤8: æµ‹è¯•æœç´¢åŠŸèƒ½")
        sample_queries = [
            ("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ", "hybrid"),
            ("æ·±åº¦å­¦ä¹ æœ‰å“ªäº›ä¸»è¦æ¶æ„ï¼Ÿ", "semantic"),
            ("Pythonæœ‰å“ªäº›æ•°æ®ç§‘å­¦å·¥å…·ï¼Ÿ", "keyword"),
            ("å¦‚ä½•è¿›è¡Œæ¨¡å‹ä¼˜åŒ–ï¼Ÿ", "hybrid")
        ]
        
        for query, search_type in sample_queries:
            try:
                search_result = await tester.search_knowledge_base(kb_id, query, search_type)
                print(f"  Q: {query} (ç±»å‹: {search_type})")
                if search_result.get("results"):
                    print(f"  A: æ‰¾åˆ° {len(search_result['results'])} ä¸ªç»“æœ")
                    for i, result in enumerate(search_result["results"][:2]):  # åªæ˜¾ç¤ºå‰2ä¸ªç»“æœ
                        print(f"    ç»“æœ{i+1}: {result.get('snippet', result.get('content', ''))[:100]}...")
                else:
                    print(f"  A: {search_result}")
                print()
            except Exception as e:
                print(f"âŒ æœç´¢å¤±è´¥ '{query}': {str(e)}")
        
        # æ­¥éª¤9: æµ‹è¯•æ–‡æ¡£ç®¡ç†åŠŸèƒ½
        print(f"\nğŸ“‹ æ­¥éª¤9: æµ‹è¯•æ–‡æ¡£ç®¡ç†åŠŸèƒ½")
        if uploaded_files:
            # æµ‹è¯•æ–‡æ¡£åˆ—è¡¨
            try:
                doc_list = await tester.list_documents(kb_id)
                print(f"âœ“ æ–‡æ¡£åˆ—è¡¨: æ‰¾åˆ° {doc_list.get('total_count', 0)} ä¸ªæ–‡æ¡£")
                for doc in doc_list.get("documents", [])[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                    print(f"  - {doc.get('filename')} (ID: {doc.get('id')}, çŠ¶æ€: {doc.get('status')})")
            except Exception as e:
                print(f"âŒ è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")
            
            # æµ‹è¯•æ–‡æ¡£è¯¦æƒ…
            if uploaded_files:
                file_id = uploaded_files[0]
                try:
                    doc_info = await tester.get_document_info(file_id)
                    print(f"âœ“ æ–‡æ¡£è¯¦æƒ…: {doc_info.get('filename')} ({doc_info.get('file_size', 0)} bytes)")
                except Exception as e:
                    print(f"âŒ è·å–æ–‡æ¡£è¯¦æƒ…å¤±è´¥: {str(e)}")
                
                try:
                    doc_content = await tester.get_document_content(file_id)
                    content_preview = doc_content.get("content", "")[:150] + "..." if len(doc_content.get("content", "")) > 150 else doc_content.get("content", "")
                    print(f"âœ“ æ–‡æ¡£å†…å®¹é¢„è§ˆ: {content_preview}")
                except Exception as e:
                    print(f"âŒ è·å–æ–‡æ¡£å†…å®¹å¤±è´¥: {str(e)}")
        
        # æ­¥éª¤10: æµ‹è¯•çŸ¥è¯†åº“åˆ—è¡¨
        print(f"\nğŸ“ æ­¥éª¤10: æµ‹è¯•çŸ¥è¯†åº“åˆ—è¡¨")
        try:
            kb_list = await tester.list_knowledge_bases()
            print(f"âœ“ çŸ¥è¯†åº“åˆ—è¡¨: {kb_list}")
            if kb_list.get("knowledge_bases"):
                print(f"  æ€»è®¡ {kb_list.get('total_count', 0)} ä¸ªçŸ¥è¯†åº“")
                for kb in kb_list["knowledge_bases"][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"  - {kb.get('name')} (ID: {kb.get('id')}, çŠ¶æ€: {kb.get('status')})")
        except Exception as e:
            print(f"âŒ è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {str(e)}")
        
        return kb_id, uploaded_files

async def cleanup_demo(kb_id: str):
    """æ¸…ç†æ¼”ç¤ºæ•°æ®"""
    print(f"\nğŸ§¹ æ¸…ç†æ¼”ç¤ºæ•°æ®...")
    
    async with BackendTester() as tester:
        try:
            result = await tester.delete_knowledge_base(kb_id)
            print(f"âœ“ æ¸…ç†å®Œæˆ: {result}")
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†å¤±è´¥: {str(e)}")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ åç«¯æœåŠ¡APIæµ‹è¯•")
    print("ğŸ¯ æµ‹è¯•å®Œæ•´çš„çŸ¥è¯†åº“APIç«¯ç‚¹å’Œæ–‡æ¡£å¤„ç†åŠŸèƒ½")
    print("=" * 60)
    
    try:
        # è¿è¡Œä¸»è¦æµ‹è¯•
        result = await demonstrate_backend_api()
        
        if result and len(result) == 2:
            kb_id, uploaded_files = result
        else:
            kb_id = result
            uploaded_files = []
        
        if kb_id:
            # æµ‹è¯•æ€»ç»“
            print("\n" + "=" * 60)
            print("ğŸ‰ APIæµ‹è¯•å®Œæˆï¼")
            print("=" * 60)
            
            print("âœ… æˆåŠŸæµ‹è¯•çš„åŠŸèƒ½:")
            print("  â€¢ æœåŠ¡å¥åº·æ£€æŸ¥ (/health, /status)")
            print("  â€¢ çŸ¥è¯†åº“åˆ›å»º (POST /api/v1/knowledge-base/create)")
            print("  â€¢ æ–‡æ¡£ä¸Šä¼  (POST /api/v1/document/upload)")
            print("  â€¢ çŸ¥è¯†åº“æ„å»º (POST /api/v1/knowledge-base/{kb_id}/build)")
            print("  â€¢ æ„å»ºçŠ¶æ€æŸ¥è¯¢ (GET /api/v1/knowledge-base/{kb_id}/build/status)")
            print("  â€¢ çŸ¥è¯†åº“éªŒè¯ (POST /api/v1/knowledge-base/{kb_id}/validate)")
            print("  â€¢ çŸ¥è¯†åº“è¯¦ç»†ä¿¡æ¯ (GET /api/v1/knowledge-base/{kb_id})")
            print("  â€¢ å¤šç±»å‹æœç´¢åŠŸèƒ½ (POST /api/v1/knowledge-base/{kb_id}/search)")
            print("  â€¢ æ–‡æ¡£ç®¡ç†åŠŸèƒ½ (GET /api/v1/document/, GET /api/v1/document/{file_id})")
            print("  â€¢ æ–‡æ¡£å†…å®¹è·å– (GET /api/v1/document/{file_id}/content)")
            print("  â€¢ çŸ¥è¯†åº“åˆ—è¡¨ (GET /api/v1/knowledge-base/)")
            print("  â€¢ çŸ¥è¯†åº“åˆ é™¤ (DELETE /api/v1/knowledge-base/{kb_id})")
            
            # è¯¢é—®æ˜¯å¦æ¸…ç†
            try:
                response = input("\nâ“ æ˜¯å¦æ¸…ç†æµ‹è¯•æ•°æ®ï¼Ÿ(y/N): ").strip().lower()
                if response in ['y', 'yes']:
                    await cleanup_demo(kb_id)
                else:
                    print(f"ğŸ“ æµ‹è¯•æ•°æ®ä¿ç•™ï¼ŒçŸ¥è¯†åº“ID: {kb_id}")
            except KeyboardInterrupt:
                print(f"\nğŸ“ æµ‹è¯•æ•°æ®ä¿ç•™ï¼ŒçŸ¥è¯†åº“ID: {kb_id}")
        else:
            print("\nâŒ æµ‹è¯•æœªèƒ½å®Œæˆï¼Œè¯·æ£€æŸ¥åç«¯æœåŠ¡çŠ¶æ€")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())